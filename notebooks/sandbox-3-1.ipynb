{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714464d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "import tarfile\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34d54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ece_19kb_df = FASTAFile.from_file('../data/data/linear_ece_19kb.fa').to_df(parse_description=False)\n",
    "linear_ece_19kb_df.index = [id_.split('.')[-1] for id_ in linear_ece_19kb_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldseek_load(path):\n",
    "   '''This loads the result of running Foldseek against all databases accessible on the Foldseek web interface.'''\n",
    "   archive = tarfile.open(path, mode='r:gz')\n",
    "   cols = ['id_','subject_id','identity','alignment_length', 'mismatch', 'gap_open', 'query_alignment_start', 'query_alignment_stop', 'subject_alignment_start', 'subject_alignment_stop']\n",
    "   cols += ['tm_score', 'e_value','bit_score', 'query_length', 'subject_length',  'query_alignment', 'subject_alignment', 'per_residue_lddt', 'subject_seq', 'subject_taxonomy_id', 'subject_species_name']\n",
    "   \n",
    "   foldseek_df = list()\n",
    "   for member in archive.getmembers():\n",
    "      if ('report' in member.name):\n",
    "         continue \n",
    "      f = archive.extractfile(member)\n",
    "      content = f.read().decode('utf-8')\n",
    "      df = pd.read_csv(io.StringIO(content), sep='\\t', names=cols)\n",
    "      df['database'] = member.name.replace('.m8', '').replace('alis_', '')\n",
    "      if len(df) > 0:\n",
    "         foldseek_df.append(df)\n",
    "\n",
    "   if len(foldseek_df) == 0:\n",
    "      return pd.DataFrame([])\n",
    "   \n",
    "   foldseek_df = pd.concat(foldseek_df).reset_index(drop=True)\n",
    "   foldseek_df['id_'] = re.search(r'\\d+_\\d+', path).group(0)\n",
    "   foldseek_df['subject_species_name'] = foldseek_df['subject_species_name'].fillna('none')\n",
    "   return foldseek_df\n",
    "\n",
    "foldseek_df = pd.concat([foldseek_load(path) for path in glob.glob('../data/foldseek/esmfold/*')])\n",
    "foldseek_df = pd.concat([foldseek_df] + [foldseek_load(path) for path in glob.glob('../data/foldseek/alphafold/*')])\n",
    "# foldseek_df.to_csv('../data/foldseek/linear_ece_19kb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee24d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. linear_ece_19kb proteins with hits: 30\n",
      "Num. linear_ece_19kb proteins with hits passing the filter: 21\n"
     ]
    }
   ],
   "source": [
    "foldseek_df['query_original_length'] = foldseek_df.id_.map(linear_ece_19kb_df.seq.apply(len)) # Foldseek search was done on trimmed structures, so want to re-add original sequence length. \n",
    "foldseek_df['query_alignment_length'] = (foldseek_df.query_alignment_stop - foldseek_df.query_alignment_start)\n",
    "foldseek_df['query_coverage'] = foldseek_df.query_alignment_length / foldseek_df.query_original_length\n",
    "# foldseek_df = foldseek_df[~foldseek_df.query_original_length.isnull()].copy() # Some of the reverse-strand ORFs are included.\n",
    "\n",
    "print(f'Num. {ece_id} proteins with hits:', foldseek_df.id_.nunique())\n",
    "\n",
    "mask = (foldseek_df.query_alignment_length > 15) | (foldseek_df.query_coverage > 0.5)\n",
    "mask = mask & (foldseek_df.tm_score > 0.7)\n",
    "foldseek_df = foldseek_df[mask].copy()\n",
    "\n",
    "print(f'Num. {ece_id} proteins with hits passing the filter:', foldseek_df.id_.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff3a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 38324 out of 38411 Foldseek hits.\n"
     ]
    }
   ],
   "source": [
    "# From ChatGPT (so take with a grain of salt), not all Mgnify (and other) IDs are in UniParc; some are directly from metagenome FASTA files. \n",
    "uniparc_id_pattern = r'(?P<id>[a-zA-Z\\d]{4,})'\n",
    "uniparc_id_pattern_protvar = r'(?P<id_1>[a-zA-Z\\d]+)(\\-[0-9])*_(?P<id_2>[a-zA-Z\\d]+)(\\-[0-9])*_(?P<chain>[A-Z])'\n",
    "uniparc_version_pattern = r'(?P<version>\\d+)'\n",
    "description_pattern = r'(?P<description>.*)'\n",
    "pdb_id_pattern = r'(?P<id>[a-z0-9]{4})'\n",
    "pdb_chain_pattern = r'(?P<chain>([A-Z0-9a-z])|([A-Z0-9a-z]-\\d))'\n",
    "pdb_assembly_pattern = r'(?P<assembly>\\d)'\n",
    "gmgc_id_pattern = r'(?P<id>GMGC.+)\\.pdb*' # These are not often not associated with UniParc (or other database) entries.\n",
    "mgnify_id_pattern = r'(?P<id>MGYP\\d+)'\n",
    "\n",
    "\n",
    "subject_id_patterns = dict() \n",
    "subject_id_patterns[rf'LevyLab_{uniparc_id_pattern}_V\\d_\\d_relaxed_{pdb_chain_pattern}'] = 'UniParc'\n",
    "subject_id_patterns[rf'AF-{uniparc_id_pattern}-{uniparc_version_pattern}-F1-model_v\\d {description_pattern}'] = 'UniParc'\n",
    "subject_id_patterns[rf'AF-{uniparc_id_pattern}-F1-model_v\\d {description_pattern}'] = 'UniParc'\n",
    "subject_id_patterns[rf'{mgnify_id_pattern}\\.pdb\\.gz'] = 'Mgnify'\n",
    "subject_id_patterns[rf'{uniparc_id_pattern}_unrelaxed_rank_\\d+_alphafold\\d_ptm_model_\\d_seed_\\d+'] = 'UniParc'\n",
    "subject_id_patterns[rf'{uniparc_id_pattern}_{uniparc_version_pattern}_unrelaxed_rank_\\d+_alphafold\\d_ptm_model_\\d_seed_\\d+'] = 'UniParc'\n",
    "subject_id_patterns[rf'af_{uniparc_id_pattern}.+'] = 'UniParc'\n",
    "subject_id_patterns[rf'{pdb_id_pattern}{pdb_chain_pattern}\\d\\d'] = 'PDB'\n",
    "subject_id_patterns[rf'{pdb_id_pattern}-assembly{pdb_assembly_pattern}\\.cif\\.gz_{pdb_chain_pattern} {description_pattern}'] = 'PDB'\n",
    "subject_id_patterns[rf'{pdb_id_pattern}-assembly{pdb_assembly_pattern}\\.cif\\.gz_{pdb_chain_pattern} {description_pattern}'] = 'PDB'\n",
    "subject_id_patterns[rf'ProtVar_{uniparc_id_pattern_protvar}'] = 'UniParc'\n",
    "subject_id_patterns[mgnify_id_pattern] = 'Mgnify'\n",
    "subject_id_patterns[gmgc_id_pattern] = 'GMGC'\n",
    "\n",
    "subject_id_df = list()\n",
    "\n",
    "def get_uniparc_id_from_protvar_id(info:dict):\n",
    "    '''In these cases, chain is not the actual chain, but seems to indicate the specific sequence in the pair.'''\n",
    "    if 'id_1' not in info:\n",
    "        return info\n",
    "    return {'id':info['id_1']} if (info['chain'] == 'A') else {'id':info['id_2']}\n",
    "\n",
    "subject_ids_no_match = list()\n",
    "\n",
    "for subject_id in foldseek_df.subject_id:\n",
    "    \n",
    "    if subject_id.startswith('ModelArchive') or subject_id.startswith('Predictome'):\n",
    "        continue # These IDs are messing things up, easier to just skip them. \n",
    "\n",
    "    for pattern, database in subject_id_patterns.items():\n",
    "        match = re.search(pattern, subject_id)\n",
    "        if match is not None:\n",
    "            info = get_uniparc_id_from_protvar_id(match.groupdict())\n",
    "            info['foldseek_id'] = subject_id # Store the original ID. \n",
    "            info['database'] = database\n",
    "            subject_id_df.append(info)\n",
    "            break\n",
    "\n",
    "subject_id_df = pd.DataFrame(subject_id_df)\n",
    "subject_id_df['id'] = [f'{row.id}_{row.chain}' if (row.database == 'PDB') else row.id for row in subject_id_df.itertuples()]\n",
    "\n",
    "print(f'Matched {len(subject_id_df)} out of {len(foldseek_df)} Foldseek hits.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e283a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _uniparc_get_metadata(id_:str):\n",
    "    df = list()\n",
    "\n",
    "    url = f'https://rest.uniprot.org/uniparc/search?query=\"{id_}\"'\n",
    "    result = requests.get(url).text \n",
    "    result = json.loads(result)['results'][0]\n",
    "\n",
    "    info = dict()\n",
    "    info['id'] = id_\n",
    "    info['uniparc_id'] = result['uniParcId'] # The actual U* UniParc ID. \n",
    "    # Note that this only grabs info for the first taxon.\n",
    "    info['taxonomy_toplevel'] = result['commonTaxons'][0]['topLevel']\n",
    "    info['taxonomy'] = result['commonTaxons'][0]['commonTaxon']\n",
    "    info['seq'] = result['sequence']['value']\n",
    "\n",
    "    annotations = result.get('sequenceFeatures', [])\n",
    "    info['n_annotations'] = len(annotations)\n",
    "    if len(annotations) == 0:\n",
    "        return pd.DataFrame([info])\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        annotation = annotation\n",
    "        info_ = info.copy()\n",
    "        info_['annotation_interpro_id'] = annotation.get('interproGroup', {}).get('id', 'none')\n",
    "        info_['annotation_interpro_description'] = annotation.get('interproGroup', {}).get('name', 'none')\n",
    "        info_['annotation_database'] = annotation['database']\n",
    "        info_['annotation_id'] = annotation['databaseId']\n",
    "        info_['annotation_start'] = annotation['locations'][0]['start']\n",
    "        info_['annotation_stop'] = annotation['locations'][0]['end']\n",
    "        df.append(info_)\n",
    "\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def uniparc_get_metadata(ids:list):\n",
    "    ids = np.unique(ids) # Make sure not to download stuff twice. \n",
    "    metadata_df = list()\n",
    "    for id_ in tqdm(ids, desc='uniparc_get_metadata: Downloading UniParc metadata.'):\n",
    "        try:\n",
    "            metadata_df.append(_uniparc_get_metadata(id_))\n",
    "        except:\n",
    "            print(f'uniparc_get_metadata: Failed on ID {id_}.')\n",
    "    metadata_df = pd.concat(metadata_df)\n",
    "    return metadata_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c89c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 140 PDB entries with no UniProt accession.\n"
     ]
    }
   ],
   "source": [
    "def _pdb_get_mappings(id_:str):\n",
    "    id_, chain = id_.split('_')\n",
    "    url = f'https://www.ebi.ac.uk/pdbe/api/mappings/uniprot/{id_}'\n",
    "    print(requests.get(url).text)\n",
    "    result = json.loads(requests.get(url).text)[id_]['UniProt']\n",
    "    result = {uniprot_id:mappings['mappings'] for uniprot_id, mappings in result.items()}\n",
    "    mappings = {f\"{id_}_{mapping['chain_id']}\":uniprot_id  for uniprot_id, mappings in result.items() for mapping in mappings}\n",
    "    return mappings\n",
    "\n",
    "\n",
    "def pdb_get_mappings(ids:pd.DataFrame, path:str='../data/foldseek/pdb-uniprot_map.json'):\n",
    "    if os.path.exists(path):\n",
    "         with open(path, 'rb') as f:\n",
    "            mappings = json.load(f)\n",
    "            return mappings\n",
    "         \n",
    "    mappings = dict()\n",
    "    for id_ in tqdm(ids, desc='pdb_get_mappings: Downloading PDB mappings.'):\n",
    "        try:\n",
    "            mappings.update(_pdb_get_mappings(id_))\n",
    "        except:\n",
    "            print(f'pdb_get_mappings: Failed on PDB ID {id_}.')\n",
    "    with open(path, 'w') as f:\n",
    "            json.dump(mappings, f)\n",
    "    return mappings\n",
    "\n",
    "ids = subject_id_df[subject_id_df.database == 'PDB']['id'].unique() \n",
    "pdb_mappings = pdb_get_mappings(ids)\n",
    "\n",
    "subject_id_df['pdb_id'] = np.where(subject_id_df.database == 'PDB', subject_id_df['id'], 'none')\n",
    "subject_id_df['id'] = np.where(subject_id_df.database == 'PDB', subject_id_df['id'].map(pdb_mappings), subject_id_df['id'])\n",
    "print(f'Removing {subject_id_df['id'].isnull().sum()} PDB entries with no UniProt accession.')\n",
    "subject_id_df = subject_id_df[~subject_id_df['id'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2ba24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/foldseek/uniparc_metadata.csv'):\n",
    "    ids = subject_id_df[subject_id_df.database.isin(['UniParc', 'PDB'])]['id'].tolist()\n",
    "    uniparc_metadata_df = uniparc_get_metadata(ids)\n",
    "    uniparc_metadata_df.to_csv('../data/foldseek/uniparc_metadata.csv')\n",
    "uniparc_metadata_df = pd.read_csv('../data/foldseek/uniparc_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682b5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldseek_df['id'] = foldseek_df['subject_id'].map(subject_id_df.drop_duplicates('foldseek_id').set_index('foldseek_id')['id'])\n",
    "foldseek_df['subject_database'] = foldseek_df['id'].map(subject_id_df.drop_duplicates('id').set_index('id')['database'])\n",
    "foldseek_df['subject_description'] = foldseek_df['id'].map(subject_id_df.drop_duplicates('id').set_index('id')['description'])\n",
    "\n",
    "if 'annotation_database' not in foldseek_df.columns:\n",
    "    foldseek_df = foldseek_df.merge(uniparc_metadata_df, left_on='id', right_on='id', how='left')\n",
    "\n",
    "get_annotation_overlap = lambda row : max(min(row.subject_alignment_stop, row.annotation_stop) - max(row.subject_alignment_start, row.annotation_start), 0)\n",
    "has_annotation = lambda row : row.annotation_start in np.arange(0, 1000)\n",
    "foldseek_df['annotation_overlap'] = [get_annotation_overlap(row) if has_annotation(row) else np.nan for row in foldseek_df.itertuples()]\n",
    "foldseek_df['annotation_coverage'] = foldseek_df.annotation_overlap / (foldseek_df.annotation_stop - foldseek_df.annotation_start)\n",
    "foldseek_df['query_coverage'] = (foldseek_df.query_alignment_stop - foldseek_df.query_alignment_start) / foldseek_df.query_length\n",
    "\n",
    "# Remove annotations that don't overlap the alignment. \n",
    "# mask = (foldseek_df.n_annotations > 1) & (foldseek_df.annotation_overlap < 10)\n",
    "# print(f'Removing {mask.sum()} useless annotations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1189cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE genes with no good hits: 1_4 1_5 1_6 1_7 1_9 1_13 1_15 1_16 1_18 1_22 1_24 1_27 1_29 1_30 1_31 1_34 1_36\n"
     ]
    }
   ],
   "source": [
    "ece_gene_ids = [f'1_{i + 1}' for i in range(38)]\n",
    "print('ECE genes with no good hits:', ' '.join([gene_id for gene_id in ece_gene_ids if (gene_id not in foldseek_df.id_.unique())]))\n",
    "ece_gene_ids_no_hits = '1_4 1_5 1_6 1_7 1_9 1_13 1_15 1_16 1_18 1_22 1_24 1_27 1_29 1_30 1_31 1_34 1_36'.split()\n",
    "# len(ece_gene_ids_no_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41225566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query sequence length: 69 (trimmed length 57)\n",
      "Num hits: 30\n",
      "Num. Mgnify hits: 20\n",
      "Num. hits to uncharacterized proteins: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxonomy</th>\n",
       "      <th>annotation_coverage</th>\n",
       "      <th>query_coverage</th>\n",
       "      <th>annotation_interpro_description</th>\n",
       "      <th>tm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37750</th>\n",
       "      <td>Alphaproteobacteria bacterium HGW-Alphaproteob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37752</th>\n",
       "      <td>Streptomyces qinglanensis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37747</th>\n",
       "      <td>Hyphomicrobiales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37751</th>\n",
       "      <td>Gammaproteobacteria bacterium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37749</th>\n",
       "      <td>Clostridium sp. CAG:510</td>\n",
       "      <td>0.202073</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>Chromate transporter</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37748</th>\n",
       "      <td>Clostridium sp. CAG:510</td>\n",
       "      <td>0.211055</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>Chromate Ion Transporter</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37754</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37743</th>\n",
       "      <td>Oscillospiraceae bacterium</td>\n",
       "      <td>0.220430</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>Chromate Ion Transporter</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37744</th>\n",
       "      <td>Oscillospiraceae bacterium</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>Chromate transporter</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37745</th>\n",
       "      <td>Trifolium subterraneum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37746</th>\n",
       "      <td>Bifidobacterium pseudocatenulatum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>Ustilago sp. UG-2017a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                taxonomy  annotation_coverage  \\\n",
       "37750  Alphaproteobacteria bacterium HGW-Alphaproteob...                  NaN   \n",
       "37752                          Streptomyces qinglanensis                  NaN   \n",
       "37747                                   Hyphomicrobiales                  NaN   \n",
       "37751                      Gammaproteobacteria bacterium                  NaN   \n",
       "37749                            Clostridium sp. CAG:510             0.202073   \n",
       "37748                            Clostridium sp. CAG:510             0.211055   \n",
       "37754                                                NaN                  NaN   \n",
       "37743                         Oscillospiraceae bacterium             0.220430   \n",
       "37744                         Oscillospiraceae bacterium             0.211111   \n",
       "37745                             Trifolium subterraneum                  NaN   \n",
       "37746                  Bifidobacterium pseudocatenulatum                  NaN   \n",
       "37753                              Ustilago sp. UG-2017a                  NaN   \n",
       "\n",
       "       query_coverage annotation_interpro_description  tm_score  \n",
       "37750        0.964912                             NaN     0.817  \n",
       "37752        0.947368                             NaN     0.720  \n",
       "37747        0.859649                             NaN     0.872  \n",
       "37751        0.824561                             NaN     0.772  \n",
       "37749        0.771930            Chromate transporter     0.837  \n",
       "37748        0.771930        Chromate Ion Transporter     0.837  \n",
       "37754        0.771930                             NaN     0.872  \n",
       "37743        0.754386        Chromate Ion Transporter     0.949  \n",
       "37744        0.754386            Chromate transporter     0.949  \n",
       "37745        0.754386                             NaN     0.941  \n",
       "37746        0.736842                             NaN     0.933  \n",
       "37753        0.666667                             NaN     0.720  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_info(id_:str, min_annotation_overlap:int=10, min_annotation_coverage:float=0.5, annotations_only:bool=False):\n",
    "    df = foldseek_df[foldseek_df.id_ == id_].copy()\n",
    "    print('Query sequence length:', df.query_original_length.iloc[0], f'(trimmed length {df.query_length.iloc[0]})')\n",
    "    print('Num hits:', df['id'].nunique())\n",
    "    print('Num. Mgnify hits:', (df.drop_duplicates('id').subject_database == 'Mgnify').sum())\n",
    "    df = df[df.subject_database != 'Mgnify'].copy()\n",
    "    print('Num. hits to uncharacterized proteins:', (df.drop_duplicates('id').n_annotations == 0).sum())\n",
    "    if annotations_only:\n",
    "        df = df[(df.n_annotations > 0) & (df.annotation_overlap > min_annotation_overlap) & (df.annotation_coverage > min_annotation_coverage)].copy()\n",
    "    return df.sort_values('query_coverage', ascending=False)\n",
    "\n",
    "print_info('1_10', annotations_only=False)[['taxonomy', 'annotation_coverage', 'query_coverage', 'annotation_interpro_description', 'tm_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a03e30da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_', 'subject_id', 'identity', 'alignment_length', 'mismatch',\n",
       "       'gap_open', 'query_alignment_start', 'query_alignment_stop',\n",
       "       'subject_alignment_start', 'subject_alignment_stop', 'tm_score',\n",
       "       'e_value', 'bit_score', 'query_length', 'subject_length',\n",
       "       'query_alignment', 'subject_alignment', 'per_residue_lddt',\n",
       "       'subject_seq', 'subject_taxonomy_id', 'subject_species_name',\n",
       "       'database', 'query_original_length', 'query_alignment_length',\n",
       "       'query_coverage', 'id', 'subject_database', 'subject_description',\n",
       "       'Unnamed: 0', 'uniparc_id', 'taxonomy_toplevel', 'taxonomy', 'seq',\n",
       "       'n_annotations', 'annotation_interpro_id',\n",
       "       'annotation_interpro_description', 'annotation_database',\n",
       "       'annotation_id', 'annotation_start', 'annotation_stop',\n",
       "       'annotation_overlap', 'annotation_coverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldseek_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5bef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banfield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
